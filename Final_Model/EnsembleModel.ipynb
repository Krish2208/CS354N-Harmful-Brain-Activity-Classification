{"cells":[{"cell_type":"markdown","metadata":{},"source":["# >> Model 1 <<"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-26T14:16:02.140268Z","iopub.status.busy":"2024-03-26T14:16:02.140005Z","iopub.status.idle":"2024-03-26T14:16:11.937156Z","shell.execute_reply":"2024-03-26T14:16:11.935874Z","shell.execute_reply.started":"2024-03-26T14:16:02.140245Z"},"papermill":{"duration":6.539764,"end_time":"2024-03-10T23:52:16.832954","exception":false,"start_time":"2024-03-10T23:52:10.29319","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Importing Libraries\n","import os\n","import gc\n","import sys\n","import math\n","import time\n","import random\n","import datetime as dt\n","import numpy as np\n","import pandas as pd\n","\n","from glob import glob\n","from pathlib import Path\n","from typing import Dict, List, Union\n","from scipy.signal import butter, lfilter, freqz\n","from matplotlib import pyplot as plt\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","sys.path.append(\"/kaggle/input/kaggle-kl-div\")\n","from kaggle_kl_div import score\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# Set device to CUDA if available\n","device = torch.device(\"cuda\")\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","# Print system information (assuming these are available in the environment)\n","!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\n","print(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n","\n","try:\n","    print(\n","        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n","    )\n","    print(\n","        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n","    )\n","    print(\n","        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n","    )\n","except Exception:\n","    pass"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019022,"end_time":"2024-03-10T23:52:16.871625","exception":false,"start_time":"2024-03-10T23:52:16.852603","status":"completed"},"tags":[]},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:11.940154Z","iopub.status.busy":"2024-03-26T14:16:11.939395Z","iopub.status.idle":"2024-03-26T14:16:11.951442Z","shell.execute_reply":"2024-03-26T14:16:11.950533Z","shell.execute_reply.started":"2024-03-26T14:16:11.940117Z"},"papermill":{"duration":0.034394,"end_time":"2024-03-10T23:52:16.926181","exception":false,"start_time":"2024-03-10T23:52:16.891787","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class CFG:\n","    VERSION = 88  # Version of the configuration (for tracking changes)\n","\n","    # Model parameters\n","    model_name = \"resnet1d_gru\"  # Name of the deep learning model to use\n","\n","    # Training and data parameters\n","    seed = 2024  # Random seed for reproducibility\n","    batch_size = 32  # Number of samples per training batch\n","    num_workers = 0  # Number of worker threads for data loading (set to 0 for simplicity)\n","\n","    # Feature extraction parameters\n","    fixed_kernel_size = 5  # Fixed kernel size for convolutions\n","    kernels = [3, 5, 7, 9, 11]  # List of kernel sizes to use for convolutions\n","    linear_layer_features = 304  # Number of features after the final linear layer (controls model complexity)\n","\n","    # Data windowing and sampling parameters\n","    seq_length = 50  # Length of the EEG data window in seconds\n","    sampling_rate = 200  # Sampling rate of the EEG data in Hz\n","    nsamples = seq_length * sampling_rate  # Total number of samples in a window\n","    out_samples = nsamples // 5  # Number of output samples after downsampling (used for prediction)\n","\n","    # bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n","    # rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n","    freq_channels = []  # List of frequency bands to extract using additional filtering [(low_cut, high_cut)]\n","\n","    # Additional filtering parameters\n","    filter_order = 2  # Order of the filter (controls filter sharpness)\n","    random_close_zone = 0.0  # Probability of skipping feature pairs during training\n","\n","    # Target labels and columns\n","    target_cols = [\n","        \"seizure_vote\",\n","        \"lpd_vote\",\n","        \"gpd_vote\",\n","        \"lrda_vote\",\n","        \"grda_vote\",\n","        \"other_vote\",\n","    ]  # List of target labels in the dataset\n","\n","    # target_preds = [x + \"_pred\" for x in target_cols]  # List of predicted label column names\n","    # label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}  # Mapping labels to numeric values\n","    # num_to_label = {v: k for k, v in label_to_num.items()}  # Mapping numeric values to labels\n","\n","    # Feature pairs for difference calculations\n","    map_features = [\n","        (\"Fp1\", \"T3\"),\n","        (\"T3\", \"O1\"),\n","        (\"Fp1\", \"C3\"),\n","        (\"C3\", \"O1\"),\n","        (\"Fp2\", \"C4\"),\n","        (\"C4\", \"O2\"),\n","        (\"Fp2\", \"T4\"),\n","        (\"T4\", \"O2\"),\n","        # ('Fz', 'Cz'), ('Cz', 'Pz'),  # Additional feature pairs (commented out)\n","    ]  # List of EEG channel pairs to calculate differences between\n","\n","    # EEG features used for the model\n","    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz']\n","        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']                    \n","    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n","    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n","\n","    # Derived parameters based on configuration\n","    n_map_features = len(map_features)\n","    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n","    target_size = len(target_cols)\n","    \n","    PATH = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n","    test_eeg = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n","    test_csv = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:11.952734Z","iopub.status.busy":"2024-03-26T14:16:11.952427Z","iopub.status.idle":"2024-03-26T14:16:11.97128Z","shell.execute_reply":"2024-03-26T14:16:11.970591Z","shell.execute_reply.started":"2024-03-26T14:16:11.952688Z"},"papermill":{"duration":0.027178,"end_time":"2024-03-10T23:52:16.973166","exception":false,"start_time":"2024-03-10T23:52:16.945988","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["koef_1 = 1.0\n","model_weights = [\n","    {\n","        'bandpass_filter':{'low':0.5, 'high':20, 'order':2}, # Configuration for bandpass filter used during training\n","        'file_data': \n","        [\n","            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v82/pop_1_weight_oof/*_best.pth\"},\n","            {'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v82/pop_2_weight_oof/*_best.pth\"},\n","        ]\n","    },\n","]"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.020315,"end_time":"2024-03-10T23:52:17.013304","exception":false,"start_time":"2024-03-10T23:52:16.992989","status":"completed"},"tags":[]},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:11.974453Z","iopub.status.busy":"2024-03-26T14:16:11.973878Z","iopub.status.idle":"2024-03-26T14:16:11.990668Z","shell.execute_reply":"2024-03-26T14:16:11.989863Z","shell.execute_reply.started":"2024-03-26T14:16:11.97442Z"},"papermill":{"duration":0.041241,"end_time":"2024-03-10T23:52:17.075224","exception":false,"start_time":"2024-03-10T23:52:17.033983","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def init_logger(log_file=\"./test.log\"):\n","    # Initialize logger\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","def asMinutes(s):\n","    # Convert seconds to minutes and seconds\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    # Calculate time since start and estimated time remaining\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def quantize_data(data, classes):\n","    # Quantize the data using mu-law encoding\n","    mu_x = mu_law_encoding(data, classes)\n","    return mu_x  # quantized\n","\n","\n","def mu_law_encoding(data, mu):\n","    # Mu-law encoding\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","\n","def mu_law_expansion(data, mu):\n","    # Mu-law expansion\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s\n","\n","\n","def butter_bandpass(lowcut, highcut, fs, order=5):\n","    # Design a Butterworth bandpass filter\n","    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n","\n","\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    # Apply a bandpass filter to the data\n","    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n","    y = lfilter(b, a, data)\n","    return y\n","\n","\n","def butter_lowpass_filter(\n","    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n","):\n","    # Apply a lowpass filter to the data\n","    nyquist = 0.5 * sampling_rate\n","    normal_cutoff = cutoff_freq / nyquist\n","    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n","    filtered_data = lfilter(b, a, data, axis=0)\n","    return filtered_data\n","\n","\n","def denoise_filter(x):\n","    # Apply a bandpass filter to the data to remove noise\n","    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n","    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n","    y = y[0:-1:4]\n","    return y"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.01931,"end_time":"2024-03-10T23:52:17.114296","exception":false,"start_time":"2024-03-10T23:52:17.094986","status":"completed"},"tags":[]},"source":["## Parquet to EEG Signals Numpy Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:11.99242Z","iopub.status.busy":"2024-03-26T14:16:11.992072Z","iopub.status.idle":"2024-03-26T14:16:12.01251Z","shell.execute_reply":"2024-03-26T14:16:12.011847Z","shell.execute_reply.started":"2024-03-26T14:16:11.992392Z"},"papermill":{"duration":0.034541,"end_time":"2024-03-10T23:52:17.16891","exception":false,"start_time":"2024-03-10T23:52:17.134369","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def eeg_from_parquet(\n","    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n",") -> np.ndarray:\n","    \"\"\"\n","    Load EEG data from a parquet file and return a numpy array of EEG features.\n","    \"\"\"\n","\n","    # Load EEG data from parquet file\n","    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n","    rows = len(eeg)\n","\n","    # Calculate the offset to center the EEG data\n","    offset = (rows - CFG.nsamples) // 2\n","\n","    # Extract the EEG data\n","    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n","\n","    if display:\n","        plt.figure(figsize=(10, 5))\n","        offset = 0\n","\n","    # Create a numpy array to store the EEG data\n","    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n","\n","    for index, feature in enumerate(CFG.eeg_features):\n","        x = eeg[feature].values.astype(\"float32\")\n","\n","        mean = np.nanmean(x)\n","        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n","\n","        if nan_percentage < 1:\n","            x = np.nan_to_num(x, nan=mean)\n","        else:\n","            x[:] = 0\n","        data[:, index] = x\n","\n","        if display:\n","            if index != 0:\n","                offset += x.max()\n","            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n","            offset -= x.min()\n","\n","    if display:\n","        plt.legend()\n","        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n","        plt.yticks([])\n","        plt.title(f\"EEG {name}\", size=16)\n","        plt.show()\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:12.014019Z","iopub.status.busy":"2024-03-26T14:16:12.01376Z","iopub.status.idle":"2024-03-26T14:16:12.037772Z","shell.execute_reply":"2024-03-26T14:16:12.036886Z","shell.execute_reply.started":"2024-03-26T14:16:12.013997Z"},"papermill":{"duration":0.047848,"end_time":"2024-03-10T23:52:17.277004","exception":false,"start_time":"2024-03-10T23:52:17.229156","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class EEGDataset(Dataset):\n","    def __init__(\n","        self,\n","        df: pd.DataFrame,\n","        batch_size: int,\n","        eegs: Dict[int, np.ndarray],\n","        mode: str = \"train\",\n","        downsample: int = None,\n","        bandpass_filter: Dict[str, Union[int, float]] = None,\n","        rand_filter: Dict[str, Union[int, float]] = None,\n","    ):\n","        self.df = df\n","        self.batch_size = batch_size\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.downsample = downsample\n","        self.bandpass_filter = bandpass_filter\n","        self.rand_filter = rand_filter\n","        \n","    def __len__(self):\n","        \"\"\"\n","        Length of dataset.\n","        \"\"\"\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Get one item.\n","        \"\"\"\n","        X, y_prob = self.__data_generation(index)\n","        if self.downsample is not None:\n","            X = X[:: self.downsample, :]\n","        output = {\n","            \"eeg\": torch.tensor(X, dtype=torch.float32),\n","            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n","        }\n","        return output\n","\n","    def __data_generation(self, index):\n","        X = np.zeros(\n","            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n","        )  # Size=(10000, 14)\n","\n","        row = self.df.iloc[index]\n","        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n","        if CFG.nsamples != CFG.out_samples:\n","            if self.mode != \"train\":\n","                offset = (CFG.nsamples - CFG.out_samples) // 2\n","            else:\n","                #offset = random.randint(0, CFG.nsamples - CFG.out_samples)                \n","                offset = ((CFG.nsamples - CFG.out_samples) * random.randint(0, 1000)) // 1000\n","            data = data[offset:offset+CFG.out_samples,:]\n","\n","        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n","            if self.mode == \"train\" and CFG.random_close_zone > 0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n","                continue\n","                \n","            diff_feat = (\n","                data[:, CFG.feature_to_index[feat_a]]\n","                - data[:, CFG.feature_to_index[feat_b]]\n","            )  # Size=(10000,)\n","\n","            if not self.bandpass_filter is None:\n","                diff_feat = butter_bandpass_filter(\n","                    diff_feat,\n","                    self.bandpass_filter[\"low\"],\n","                    self.bandpass_filter[\"high\"],\n","                    CFG.sampling_rate,\n","                    order=self.bandpass_filter[\"order\"],\n","                )\n","                    \n","            if (\n","                self.mode == \"train\"\n","                and not self.rand_filter is None\n","                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n","            ):\n","                lowcut = random.randint(\n","                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n","                )\n","                highcut = lowcut + self.rand_filter[\"band\"]\n","                diff_feat = butter_bandpass_filter(\n","                    diff_feat,\n","                    lowcut,\n","                    highcut,\n","                    CFG.sampling_rate,\n","                    order=self.rand_filter[\"order\"],\n","                )\n","\n","            X[:, i] = diff_feat\n","\n","        n = CFG.n_map_features\n","        if len(CFG.freq_channels) > 0:\n","            for i in range(CFG.n_map_features):\n","                diff_feat = X[:, i]\n","                # Apply bandpass filter to the difference feature\n","                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n","                    band_feat = butter_bandpass_filter(\n","                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n","                    )\n","                    X[:, n] = band_feat\n","                    n += 1\n","\n","        for spml_feat in CFG.simple_features:\n","            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n","            \n","            # Apply bandpass filter to the feature\n","            if not self.bandpass_filter is None:\n","                feat_val = butter_bandpass_filter(\n","                    feat_val,\n","                    self.bandpass_filter[\"low\"],\n","                    self.bandpass_filter[\"high\"],\n","                    CFG.sampling_rate,\n","                    order=self.bandpass_filter[\"order\"],\n","                )\n","\n","            # Apply random bandpass filter to the feature with a probability\n","            if (\n","                self.mode == \"train\"\n","                and not self.rand_filter is None\n","                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n","            ):\n","                lowcut = random.randint(\n","                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n","                )\n","                highcut = lowcut + self.rand_filter[\"band\"]\n","                feat_val = butter_bandpass_filter(\n","                    feat_val,\n","                    lowcut,\n","                    highcut,\n","                    CFG.sampling_rate,\n","                    order=self.rand_filter[\"order\"],\n","                )\n","\n","            X[:, n] = feat_val\n","            n += 1\n","            \n","        X = np.clip(X, -1024, 1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n","\n","        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n","        if self.mode != \"test\":\n","            y_prob = row[CFG.target_cols].values.astype(np.float32)\n","\n","        return X, y_prob"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019333,"end_time":"2024-03-10T23:52:17.316382","exception":false,"start_time":"2024-03-10T23:52:17.297049","status":"completed"},"tags":[]},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:12.039476Z","iopub.status.busy":"2024-03-26T14:16:12.039183Z","iopub.status.idle":"2024-03-26T14:16:12.06531Z","shell.execute_reply":"2024-03-26T14:16:12.064584Z","shell.execute_reply.started":"2024-03-26T14:16:12.039454Z"},"papermill":{"duration":0.048274,"end_time":"2024-03-10T23:52:17.384117","exception":false,"start_time":"2024-03-10T23:52:17.335843","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Define the ResNet_1D_Block class\n","class ResNet_1D_Block(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        kernel_size,\n","        stride,\n","        padding,\n","        downsampling,\n","        dilation=1,\n","        groups=1,\n","        dropout=0.0,\n","    ):\n","        super(ResNet_1D_Block, self).__init__()\n","\n","        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n","        # self.relu = nn.ReLU(inplace=False)\n","        # self.relu_1 = nn.PReLU()\n","        # self.relu_2 = nn.PReLU()\n","        self.relu_1 = nn.Hardswish()\n","        self.relu_2 = nn.Hardswish()\n","\n","        self.dropout = nn.Dropout(p=dropout, inplace=False)\n","        self.conv1 = nn.Conv1d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            padding=padding,\n","            dilation=dilation,\n","            groups=groups,\n","            bias=False,\n","        )\n","\n","        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n","        self.conv2 = nn.Conv1d(\n","            in_channels=out_channels,\n","            out_channels=out_channels,\n","            kernel_size=kernel_size,\n","            stride=stride,\n","            padding=padding,\n","            dilation=dilation,\n","            groups=groups,\n","            bias=False,\n","        )\n","\n","        self.maxpool = nn.MaxPool1d(\n","            kernel_size=2,\n","            stride=2,\n","            padding=0,\n","            dilation=dilation,\n","        )\n","        self.downsampling = downsampling\n","\n","    # Define the forward pass\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.bn1(x)\n","        out = self.relu_1(out)\n","        out = self.dropout(out)\n","        out = self.conv1(out)\n","        out = self.bn2(out)\n","        out = self.relu_2(out)\n","        out = self.dropout(out)\n","        out = self.conv2(out)\n","\n","        out = self.maxpool(out)\n","        identity = self.downsampling(x)\n","\n","        out += identity\n","        return out\n","\n","\n","# Define the EEGNet class\n","class EEGNet(nn.Module):\n","    def __init__(\n","        self,\n","        kernels,\n","        in_channels,\n","        fixed_kernel_size,\n","        num_classes,\n","        linear_layer_features,\n","        dilation=1,\n","        groups=1,\n","    ):\n","        super(EEGNet, self).__init__()\n","        self.kernels = kernels\n","        self.planes = 24\n","        self.parallel_conv = nn.ModuleList()\n","        self.in_channels = in_channels\n","\n","        for i, kernel_size in enumerate(list(self.kernels)):\n","            sep_conv = nn.Conv1d(\n","                in_channels=in_channels,\n","                out_channels=self.planes,\n","                kernel_size=(kernel_size),\n","                stride=1,\n","                padding=0,\n","                dilation=dilation,\n","                groups=groups,\n","                bias=False,\n","            )\n","            self.parallel_conv.append(sep_conv)\n","\n","        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n","        # self.relu = nn.ReLU(inplace=False)\n","        # self.relu_1 = nn.ReLU()\n","        # self.relu_2 = nn.ReLU()\n","        self.relu_1 = nn.SiLU()\n","        self.relu_2 = nn.SiLU()\n","\n","        self.conv1 = nn.Conv1d(\n","            in_channels=self.planes,\n","            out_channels=self.planes,\n","            kernel_size=fixed_kernel_size,\n","            stride=2,\n","            padding=2,\n","            dilation=dilation,\n","            groups=groups,\n","            bias=False,\n","        )\n","\n","        self.block = self._make_resnet_layer(\n","            kernel_size=fixed_kernel_size,\n","            stride=1,\n","            dilation=dilation,\n","            groups=groups,\n","            padding=fixed_kernel_size // 2,\n","        )\n","        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n","        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n","\n","        self.rnn = nn.GRU(\n","            input_size=self.in_channels,\n","            hidden_size=128,\n","            num_layers=1,\n","            bidirectional=True,\n","            # dropout=0.2,\n","        )\n","\n","        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n","\n","    # Make the ResNet layer\n","    def _make_resnet_layer(\n","        self,\n","        kernel_size,\n","        stride,\n","        dilation=1,\n","        groups=1,\n","        blocks=9,\n","        padding=0,\n","        dropout=0.0,\n","    ):\n","        layers = []\n","        downsample = None\n","        base_width = self.planes\n","\n","        for i in range(blocks):\n","            downsampling = nn.Sequential(\n","                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","            )\n","            layers.append(\n","                ResNet_1D_Block(\n","                    in_channels=self.planes,\n","                    out_channels=self.planes,\n","                    kernel_size=kernel_size,\n","                    stride=stride,\n","                    padding=padding,\n","                    downsampling=downsampling,\n","                    dilation=dilation,\n","                    groups=groups,\n","                    dropout=dropout,\n","                )\n","            )\n","        return nn.Sequential(*layers)\n","\n","    # Extract features from the data\n","    def extract_features(self, x):\n","        x = x.permute(0, 2, 1)\n","        out_sep = []\n","\n","        for i in range(len(self.kernels)):\n","            sep = self.parallel_conv[i](x)\n","            out_sep.append(sep)\n","\n","        out = torch.cat(out_sep, dim=2)\n","        out = self.bn1(out)\n","        out = self.relu_1(out)\n","        out = self.conv1(out)\n","\n","        out = self.block(out)\n","        out = self.bn2(out)\n","        out = self.relu_2(out)\n","        out = self.avgpool(out)\n","\n","        out = out.reshape(out.shape[0], -1)\n","        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n","        new_rnn_h = rnn_out[:, -1, :]  # <~~\n","\n","        new_out = torch.cat([out, new_rnn_h], dim=1)\n","        return new_out\n","\n","    # Define the forward pass\n","    def forward(self, x):\n","        new_out = self.extract_features(x)\n","        result = self.fc(new_out)\n","        return result"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019167,"end_time":"2024-03-10T23:52:17.42254","exception":false,"start_time":"2024-03-10T23:52:17.403373","status":"completed"},"tags":[]},"source":["## Inference Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:12.066631Z","iopub.status.busy":"2024-03-26T14:16:12.066381Z","iopub.status.idle":"2024-03-26T14:16:12.088356Z","shell.execute_reply":"2024-03-26T14:16:12.087643Z","shell.execute_reply.started":"2024-03-26T14:16:12.06661Z"},"papermill":{"duration":0.029033,"end_time":"2024-03-10T23:52:17.470818","exception":false,"start_time":"2024-03-10T23:52:17.441785","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def inference_function(test_loader, model, device):\n","    model.eval()  # set model in evaluation mode\n","    softmax = nn.Softmax(dim=1)\n","    prediction_dict = {}\n","    preds = []\n","    with tqdm(test_loader, unit=\"test_batch\", desc=\"Inference\") as tqdm_test_loader:\n","        for step, batch in enumerate(tqdm_test_loader):\n","            X = batch.pop(\"eeg\").to(device)  # send inputs to `device`\n","            batch_size = X.size(0)\n","            with torch.no_grad():\n","                y_preds = model(X)  # forward propagation pass\n","            y_preds = softmax(y_preds)\n","            preds.append(y_preds.to(\"cpu\").numpy())  # save predictions\n","\n","    prediction_dict[\"predictions\"] = np.concatenate(\n","        preds\n","    )  # np.array() of shape (fold_size, target_cols)\n","    return prediction_dict"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.019996,"end_time":"2024-03-10T23:52:17.510701","exception":false,"start_time":"2024-03-10T23:52:17.490705","status":"completed"},"tags":[]},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:12.089796Z","iopub.status.busy":"2024-03-26T14:16:12.089466Z","iopub.status.idle":"2024-03-26T14:16:12.139082Z","shell.execute_reply":"2024-03-26T14:16:12.138187Z","shell.execute_reply.started":"2024-03-26T14:16:12.089765Z"},"papermill":{"duration":0.049954,"end_time":"2024-03-10T23:52:17.580272","exception":false,"start_time":"2024-03-10T23:52:17.530318","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Load the test data\n","test_df = pd.read_csv(CFG.test_csv)\n","print(f\"Test dataframe shape is: {test_df.shape}\")\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:12.143581Z","iopub.status.busy":"2024-03-26T14:16:12.143326Z","iopub.status.idle":"2024-03-26T14:16:12.613556Z","shell.execute_reply":"2024-03-26T14:16:12.612657Z","shell.execute_reply.started":"2024-03-26T14:16:12.143559Z"},"papermill":{"duration":0.355424,"end_time":"2024-03-10T23:52:17.956694","exception":false,"start_time":"2024-03-10T23:52:17.60127","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Load the EEG data for the test set\n","test_eeg_parquet_paths = glob(CFG.test_eeg + \"*.parquet\")\n","test_eeg_df = pd.read_parquet(test_eeg_parquet_paths[0])\n","test_eeg_features = test_eeg_df.columns\n","print(f\"There are {len(test_eeg_features)} raw eeg features\")\n","print(list(test_eeg_features))\n","del test_eeg_df\n","_ = gc.collect()\n","\n","# %%time\n","all_eegs = {}\n","eeg_ids = test_df.eeg_id.unique()\n","for i, eeg_id in tqdm(enumerate(eeg_ids)):\n","    # Save EEG to Python dictionary of numpy arrays\n","    eeg_path = CFG.test_eeg + str(eeg_id) + \".parquet\"\n","    data = eeg_from_parquet(eeg_path)\n","    all_eegs[eeg_id] = data"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.020693,"end_time":"2024-03-10T23:52:17.999826","exception":false,"start_time":"2024-03-10T23:52:17.979133","status":"completed"},"tags":[]},"source":["## Inference "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:12.615257Z","iopub.status.busy":"2024-03-26T14:16:12.614892Z","iopub.status.idle":"2024-03-26T14:16:15.352876Z","shell.execute_reply":"2024-03-26T14:16:15.351871Z","shell.execute_reply.started":"2024-03-26T14:16:12.615222Z"},"papermill":{"duration":2.135679,"end_time":"2024-03-10T23:52:20.156084","exception":false,"start_time":"2024-03-10T23:52:18.020405","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["koef_sum = 0\n","koef_count = 0\n","predictions = []\n","files = []\n","\n","for model_block in model_weights:\n","    # Create the test dataset\n","    test_dataset = EEGDataset(\n","        df=test_df,\n","        batch_size=CFG.batch_size,\n","        mode=\"test\",\n","        eegs=all_eegs,\n","        bandpass_filter=model_block['bandpass_filter']\n","    )\n","\n","    if len(predictions) == 0:\n","        output = test_dataset[0]\n","        X = output[\"eeg\"]\n","        print(f\"X shape: {X.shape}\")\n","                \n","    # Create the test data loader\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=CFG.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # Load the model\n","    model = EEGNet(\n","        kernels=CFG.kernels,\n","        in_channels=CFG.in_channels,\n","        fixed_kernel_size=CFG.fixed_kernel_size,\n","        num_classes=CFG.target_size,\n","        linear_layer_features=CFG.linear_layer_features,\n","    )\n","\n","    # Load the model weights\n","    for file_line in model_block['file_data']:\n","        koef = file_line['koef']\n","        for weight_model_file in glob(file_line['file_mask']):\n","            files.append(weight_model_file)\n","            checkpoint = torch.load(weight_model_file, map_location=device)\n","            model.load_state_dict(checkpoint[\"model\"])\n","            model.to(device)\n","            prediction_dict = inference_function(test_loader, model, device)\n","            predict = prediction_dict[\"predictions\"]\n","            predict *= koef\n","            koef_sum += koef\n","            koef_count += 1\n","            predictions.append(predict)\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","\n","# Combine the predictions\n","predictions = np.array(predictions)\n","koef_sum /= koef_count\n","predictions /= koef_sum\n","predictions = np.mean(predictions, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:15.354198Z","iopub.status.busy":"2024-03-26T14:16:15.35393Z","iopub.status.idle":"2024-03-26T14:16:15.360563Z","shell.execute_reply":"2024-03-26T14:16:15.359632Z","shell.execute_reply.started":"2024-03-26T14:16:15.354174Z"},"papermill":{"duration":0.031644,"end_time":"2024-03-10T23:52:20.209525","exception":false,"start_time":"2024-03-10T23:52:20.177881","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Save the predictions\n","predss_1 = predictions\n","predss_1"]},{"cell_type":"markdown","metadata":{},"source":["# >> Model 2 <<"]},{"cell_type":"markdown","metadata":{},"source":["## Data Generator, Model and utility functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:15.362448Z","iopub.status.busy":"2024-03-26T14:16:15.361971Z","iopub.status.idle":"2024-03-26T14:16:34.558512Z","shell.execute_reply":"2024-03-26T14:16:34.557507Z","shell.execute_reply.started":"2024-03-26T14:16:15.362416Z"},"trusted":true},"outputs":[],"source":["# Importing Libraries\n","import librosa\n","import os, random\n","import tensorflow\n","import tensorflow as tf\n","import albumentations as albu\n","import pandas as pd, numpy as np\n","from scipy.signal import butter, lfilter\n","import tensorflow.keras.backend as K, gc\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization\n","\n","# Loading the EfficientNetB2 model\n","LOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'\n","LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models'\n","MODEL = {'K+E+KE': 52}\n","for DATA_TYPE in MODEL: pass\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n","FEATS = [['Fp1','F7','T3','T5','O1'],\n","         ['Fp1','F3','C3','P3','O1'],\n","         ['Fp2','F8','T4','T6','O2'],\n","         ['Fp2','F4','C4','P4','O2']]\n","    \n","class DataGenerator():\n","    # Generates data for keras\n","    def __init__(self, data, specs=None, eeg_specs=None, raw_eegs=None , augment=False, mode='train', data_type=DATA_TYPE): \n","        self.augment = augment\n","        self.mode = mode\n","        self.data_type = data_type\n","        self.data = self.build_data(data.copy())\n","        self.specs = specs\n","        self.eeg_specs = eeg_specs\n","        self.raw_eegs = raw_eegs\n","        self.on_epoch_end()\n","    \n","    # Feature extraction\n","    def build_data(self,data):\n","        if self.data_type in ['K+E']:\n","            data_dup = pd.concat([data] * 2, ignore_index=True)\n","            data_dup.loc[:len(data),'data_type'] = 'K'\n","            data_dup.loc[len(data):,'data_type'] = 'E'\n","            data = data_dup\n","        elif self.data_type in ['K+E+KE']:\n","            data_trp = pd.concat([data] * 3, ignore_index=True)\n","            data_trp.loc[:len(data),'data_type'] = 'K'\n","            data_trp.loc[len(data):len(data)*2,'data_type'] = 'E'\n","            data_trp.loc[len(data)*2:,'data_type'] = 'KE'\n","            data = data_trp\n","        else:\n","            data['data_type'] = self.data_type\n","        return data\n","    \n","    # Length of the dataset\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","    # Returns one sample\n","    def __getitem__(self, index):\n","        X, y = self.data_generation(index)\n","        if self.augment: X = self.augmentation(X)\n","        return X, y\n","    \n","    def __call__(self):\n","        for i in range(self.__len__()):\n","            yield self.__getitem__(i)\n","            \n","            if i == self.__len__()-1:\n","                self.on_epoch_end()\n","                \n","    # Post-epoch operations\n","    def on_epoch_end(self):\n","        if self.mode=='train': \n","            self.data = self.data.sample(frac=1).reset_index(drop=True)\n","    \n","    # Data Generation\n","    def data_generation(self, index):\n","        row = self.data.iloc[index]\n","        if row.data_type == 'KE':\n","            X,y = self.generate_all_specs(index)\n","        elif row.data_type in ['K','E']:\n","            X,y = self.generate_specs(index)\n","        elif row.data_type == 'R':\n","            X,y = self.generate_raw(index)\n","        elif row.data_type in ['ER','KR']:\n","            X1,y = self.generate_specs(index)\n","            X2,y = self.generate_raw(index)\n","            X = (X1,X2)\n","        elif row.data_type in ['KER']:\n","            X1,y = self.generate_all_specs(index)\n","            X2,y = self.generate_raw(index)\n","            X = (X1,X2)\n","        return X,y\n","    \n","    # Generates All Spectrogram\n","    def generate_all_specs(self, index):\n","        X = np.zeros((512,512,3),dtype='float32')\n","        y = np.zeros((6,),dtype='float32')\n","        \n","        row = self.data.iloc[index]\n","        if self.mode=='test': \n","            offset = 0\n","        else:\n","            offset = int(row.offset/2)\n","        \n","        eeg = self.eeg_specs[row.eeg_id]\n","        spec = self.specs[row.spec_id]\n","        \n","        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n","        img = np.stack(imgs,axis=-1)\n","        # LOG TRANSFORM SPECTROGRAM\n","        img = np.clip(img,np.exp(-4),np.exp(8))\n","        img = np.log(img)\n","            \n","        # STANDARDIZE PER IMAGE\n","        img = np.nan_to_num(img, nan=0.0)    \n","            \n","        mn = img.flatten().min()\n","        mx = img.flatten().max()\n","        ep = 1e-5\n","        img = 255 * (img - mn) / (mx - mn + ep)\n","        \n","        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n","        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n","        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n","        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n","        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n","        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n","        \n","        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n","        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n","        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n","        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n","        \n","        # EEG\n","        img = eeg\n","        mn = img.flatten().min()\n","        mx = img.flatten().max()\n","        ep = 1e-5\n","        img = 255 * (img - mn) / (mx - mn + ep)\n","        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n","        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n","        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n","        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n","        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n","        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n","        \n","        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n","        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n","        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n","        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n","\n","        if self.mode!='test':\n","            y[:] = row[TARGETS]\n","        \n","        return X,y\n","    \n","    # Generates Spectrogram\n","    def generate_specs(self, index):\n","        X = np.zeros((512,512,3),dtype='float32')\n","        y = np.zeros((6,),dtype='float32')\n","        \n","        row = self.data.iloc[index]\n","        if self.mode=='test': \n","            offset = 0\n","        else:\n","            offset = int(row.offset/2)\n","        \n","        if row.data_type in ['E','ER']:\n","            img = self.eeg_specs[row.eeg_id]\n","        elif row.data_type in ['K','KR']:\n","            spec = self.specs[row.spec_id]\n","            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n","            img = np.stack(imgs,axis=-1)\n","            # LOG TRANSFORM SPECTROGRAM\n","            img = np.clip(img,np.exp(-4),np.exp(8))\n","            img = np.log(img)\n","            \n","            # STANDARDIZE PER IMAGE\n","            img = np.nan_to_num(img, nan=0.0)    \n","            \n","        mn = img.flatten().min()\n","        mx = img.flatten().max()\n","        ep = 1e-5\n","        img = 255 * (img - mn) / (mx - mn + ep)\n","        \n","        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n","        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n","        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n","        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n","        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n","        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n","        \n","        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n","        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n","        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n","        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n","        \n","        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n","        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n","        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n","        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n","        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n","        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n","        \n","        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n","        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n","        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n","        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n","        \n","        if self.mode!='test':\n","            y[:] = row[TARGETS]\n","        \n","        return X,y\n","    \n","    # Generates Raw EEG\n","    def generate_raw(self,index):\n","        if USE_PROCESSED and self.mode!='test':\n","            X = np.zeros((2_000,8),dtype='float32')\n","            y = np.zeros((6,),dtype='float32')\n","            row = self.data.iloc[index]\n","            X = self.raw_eegs[row.eeg_id]\n","            y[:] = row[TARGETS]\n","            return X,y\n","        \n","        X = np.zeros((10_000,8),dtype='float32')\n","        y = np.zeros((6,),dtype='float32')\n","        \n","        row = self.data.iloc[index]\n","        eeg = self.raw_eegs[row.eeg_id]\n","            \n","        # FEATURE ENGINEER\n","        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n","        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n","            \n","        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n","        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n","            \n","        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n","        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n","            \n","        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n","        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n","            \n","        # STANDARDIZE\n","        X = np.clip(X,-1024,1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","            \n","        # BUTTER LOW-PASS FILTER\n","        X = self.butter_lowpass_filter(X)\n","        # Downsample\n","        X = X[::5,:]\n","        \n","        if self.mode!='test':\n","            y[:] = row[TARGETS]\n","                \n","        return X,y\n","        \n","    # Butter Low-Pass Filter\n","    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n","        nyquist = 0.5 * sampling_rate\n","        normal_cutoff = cutoff_freq / nyquist\n","        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","        filtered_data = lfilter(b, a, data, axis=0)\n","        return filtered_data\n","    \n","    # Resize Image\n","    def resize(self, img,size):\n","        composition = albu.Compose([\n","                albu.Resize(size[0],size[1])\n","            ])\n","        return composition(image=img)['image']\n","        \n","    # Augmentation\n","    def augmentation(self, img):\n","        composition = albu.Compose([\n","                albu.HorizontalFlip(p=0.4)\n","            ])\n","        return composition(image=img)['image']\n","\n","# Spectrogram from EEG\n","def spectrogram_from_eeg(parquet_path):\n","    \n","    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n","    eeg = pd.read_parquet(parquet_path)\n","    middle = (len(eeg)-10_000)//2\n","    eeg = eeg.iloc[middle:middle+10_000]\n","    \n","    # VARIABLE TO HOLD SPECTROGRAM\n","    img = np.zeros((100,300,4),dtype='float32')\n","\n","    for k in range(4):\n","        COLS = FEATS[k]\n","        \n","        for kk in range(4):\n","            # FILL NANS\n","            x1 = eeg[COLS[kk]].values\n","            x2 = eeg[COLS[kk+1]].values\n","            m = np.nanmean(x1)\n","            if np.isnan(x1).mean()<1: x1 = np.nan_to_num(x1,nan=m)\n","            else: x1[:] = 0\n","            m = np.nanmean(x2)\n","            if np.isnan(x2).mean()<1: x2 = np.nan_to_num(x2,nan=m)\n","            else: x2[:] = 0\n","                \n","            # COMPUTE PAIR DIFFERENCES\n","            x = x1 - x2\n","\n","            # RAW SPECTROGRAM\n","            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n","                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n","            \n","            # LOG TRANSFORM\n","            width = (mel_spec.shape[1]//30)*30\n","            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n","            img[:,:,k] += mel_spec_db\n","                \n","        # AVERAGE THE 4 MONTAGE DIFFERENCES\n","        img[:,:,k] /= 4.0\n","          \n","    return img\n","\n","# EEG from Parquet\n","def eeg_from_parquet(parquet_path):\n","\n","    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n","    rows = len(eeg)\n","    offset = (rows-10_000)//2\n","    eeg = eeg.iloc[offset:offset+10_000]\n","    data = np.zeros((10_000,len(FEATS2)))\n","    for j,col in enumerate(FEATS2):\n","        \n","        # FILL NAN\n","        x = eeg[col].values.astype('float32')\n","        m = np.nanmean(x)\n","        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n","        else: x[:] = 0\n","        \n","        data[:,j] = x\n","\n","    return data\n","\n","def build_spec_model(hybrid=False):  \n","    inp = tf.keras.layers.Input((512,512,3))\n","    base_model = load_model(f'{LOAD_BACKBONE_FROM}')    \n","    x = base_model(inp)\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    if not hybrid:\n","        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n","    model = tf.keras.Model(inputs=inp, outputs=x)\n","    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n","    loss = tf.keras.losses.KLDivergence()\n","    model.compile(loss=loss, optimizer=opt)  \n","    return model\n","\n","def dataset(data, mode='train', batch_size=32, data_type=DATA_TYPE, \n","            augment=False, specs=None, eeg_specs=None, raw_eegs=None):\n","    \n","    gen = DataGenerator(data,mode=mode, data_type=data_type, augment=augment,\n","                       specs=specs, eeg_specs=eeg_specs, raw_eegs=raw_eegs)\n","    inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)     \n","    output_signature = (inp,tf.TensorSpec(shape=(6,), dtype=tf.float32))\n","    dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=output_signature).batch(\n","        batch_size)\n","    return dataset\n","\n","# Predict Function\n","def predict(models, params, fold, models_path=None):\n","    preds = []\n","    if models_path is None: models_path = LOAD_MODELS_FROM\n","    model = build_spec_model()\n","    for data_type in models:\n","        data = params['data']\n","        ver = models[data_type]\n","        ds = dataset(data_type=data_type, **params)\n","        model.load_weights(f'{models_path}/model_{data_type}_{ver}_{fold}.weights.h5')\n","        pred = model.predict(ds)\n","        if data_type in ['K+E+KE']:\n","            pred = (pred[:len(data)] + pred[len(data):len(data)*2] + pred[len(data)*2:])/3\n","        preds.append(pred)\n","    pred = np.mean(preds,axis=0)\n","    del model\n","    gc.collect()\n","    return pred"]},{"cell_type":"markdown","metadata":{},"source":["## Load Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:34.56199Z","iopub.status.busy":"2024-03-26T14:16:34.561344Z"},"trusted":true},"outputs":[],"source":["# READ ALL SPECTROGRAMS\n","test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n","PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\n","files2 = os.listdir(PATH2)\n","spectrograms2 = {}\n","for i,f in enumerate(files2):\n","    if i%100==0: print(i,', ',end='')\n","    tmp = pd.read_parquet(f'{PATH2}/{f}')\n","    name = int(f.split('.')[0])\n","    spectrograms2[name] = tmp.iloc[:,1:].values\n","    \n","# RENAME FOR DATA GENERATOR\n","test = test.rename({'spectrogram_id':'spec_id'},axis=1)\n","\n","# READ ALL EEG SPECTROGRAMS\n","PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n","EEG_IDS2 = test.eeg_id.unique()\n","all_eegs2 = {}\n","for i,eeg_id in enumerate(EEG_IDS2):\n","        \n","    # CREATE SPECTROGRAM FROM EEG PARQUET\n","    img = spectrogram_from_eeg(f'{PATH2}/{eeg_id}.parquet')\n","    all_eegs2[eeg_id] = img\n","\n","# READ ALL RAW EEG SIGNALS\n","all_raw_eegs2 = {}\n","for i,eeg_id in enumerate(EEG_IDS2):\n","        \n","    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n","    data = eeg_from_parquet(f'{PATH2}/{eeg_id}.parquet')\n","    all_raw_eegs2[eeg_id] = data"]},{"cell_type":"markdown","metadata":{},"source":["## Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["preds = []\n","params = {'data':test,'mode':'test','specs':spectrograms2, 'eeg_specs':all_eegs2, 'raw_eegs':all_raw_eegs2}\n","\n","for i in range(5):\n","    print(f'Fold {i+1}')\n","    pred = predict(MODEL,params,i)\n","    preds.append(pred)\n","    \n","pred = np.mean(preds,axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save the predictions\n","predss_2 = pred\n","predss_2"]},{"cell_type":"markdown","metadata":{},"source":["# >>Model 3<<"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc\n","import os\n","import random\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from IPython.display import display\n","\n","import timm\n","import torch\n","import torch.nn as nn  \n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","\n","from scipy import signal\n","\n","warnings.filterwarnings('ignore', category=Warning)\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the Config class\n","class Config:\n","    seed = 3131\n","    image_transform = transforms.Resize((512, 512))\n","    num_folds = 5\n","    dataset_wide_mean = -0.2972692229201065 #From Train notebook\n","    dataset_wide_std = 2.5997336315611026 #From Train notebook\n","    ownspec_mean = 7.29084372799223e-05 # From Train spectrograms notebook\n","    ownspec_std = 4.510082606216031 # From Train spectrograms notebook\n","    \n","# Set the seed\n","def set_seed(seed):\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","    \n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    \n","set_seed(Config.seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load the test and sample submission data\n","test_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\n","submission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n","\n","submission = submission.merge(test_df, on='eeg_id', how='left')\n","submission['path_spec'] = submission['spectrogram_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/{x}.parquet\")\n","submission['path_eeg'] = submission['eeg_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/{x}.parquet\")\n","\n","display(submission)\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["models = []\n","\n","# Load in original EfficientnetB0 model\n","for i in range(Config.num_folds):\n","    model_effnet_b0 = timm.create_model('efficientnet_b0', pretrained=False, num_classes=6, in_chans=1)\n","    model_effnet_b0.load_state_dict(torch.load(f'/kaggle/input/hms-train-efficientnetb0/efficientnet_b0_fold{i}.pth', map_location=torch.device('cpu')))\n","    models.append(model_effnet_b0)\n","    \n","models_datawide = []\n","# Load in hyperparameter optimized EfficientnetB1\n","for i in range(Config.num_folds):\n","    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n","    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/train/efficientnet_b1_fold{i}.pth', map_location=torch.device('cpu')))\n","    models_datawide.append(model_effnet_b1)\n","    \n","models_ownspec = []\n","# Load in EfficientnetB1 with new spectrograms\n","for i in range(Config.num_folds):\n","    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n","    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/efficientnet-b1-ownspectrograms/efficientnet_b1_fold{i}_datawide_CosineAnnealingLR_0.001_False.pth', map_location=torch.device('cpu')))\n","    models_ownspec.append(model_effnet_b1)\n","    \n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_predictions = []\n","\n","def create_spectrogram(data):\n","    \"\"\"This function will create a spectrogram based on EEG-data\"\"\"\n","    nperseg = 150  # Length of each segment\n","    noverlap = 128  # Overlap between segments\n","    NFFT = max(256, 2 ** int(np.ceil(np.log2(nperseg))))\n","\n","    # LL Spec = ( spec(Fp1 - F7) + spec(F7 - T3) + spec(T3 - T5) + spec(T5 - O1) )/4\n","    freqs, t,spectrum_LL1 = signal.spectrogram(data['Fp1']-data['F7'],nfft=NFFT,noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_LL2 = signal.spectrogram(data['F7']-data['T3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_LL3 = signal.spectrogram(data['T3']-data['T5'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_LL4 = signal.spectrogram(data['T5']-data['O1'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","\n","    LL = (spectrum_LL1+ spectrum_LL2 +spectrum_LL3 + spectrum_LL4)/4\n","\n","    # LP Spec = ( spec(Fp1 - F3) + spec(F3 - C3) + spec(C3 - P3) + spec(P3 - O1) )/4\n","    freqs, t,spectrum_LP1 = signal.spectrogram(data['Fp1']-data['F3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_LP2 = signal.spectrogram(data['F3']-data['C3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_LP3 = signal.spectrogram(data['C3']-data['P3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_LP4 = signal.spectrogram(data['P3']-data['O1'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","\n","    LP = (spectrum_LP1+ spectrum_LP2 +spectrum_LP3 + spectrum_LP4)/4\n","\n","    # RP Spec = ( spec(Fp2 - F4) + spec(F4 - C4) + spec(C4 - P4) + spec(P4 - O2) )/4\n","    freqs, t,spectrum_RP1 = signal.spectrogram(data['Fp2']-data['F4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_RP2 = signal.spectrogram(data['F4']-data['C4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_RP3 = signal.spectrogram(data['C4']-data['P4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_RP4 = signal.spectrogram(data['P4']-data['O2'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","\n","    RP = (spectrum_RP1+ spectrum_RP2 +spectrum_RP3 + spectrum_RP4)/4\n","\n","\n","    # RL Spec = ( spec(Fp2 - F8) + spec(F8 - T4) + spec(T4 - T6) + spec(T6 - O2) )/4\n","    freqs, t,spectrum_RL1 = signal.spectrogram(data['Fp2']-data['F8'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_RL2 = signal.spectrogram(data['F8']-data['T4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_RL3 = signal.spectrogram(data['T4']-data['T6'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    freqs, t,spectrum_RL4 = signal.spectrogram(data['T6']-data['O2'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n","    RL = (spectrum_RL1+ spectrum_RL2 +spectrum_RL3 + spectrum_RL4)/4\n","    spectogram = np.concatenate((LL, LP,RP,RL), axis=0)\n","    return spectogram\n","\n","def preprocess_ownspec(path_to_parquet):\n","    \"\"\"The data will be processed from EEG to spectrogramdata\"\"\"\n","    data = pd.read_parquet(path_to_parquet)\n","    data = create_spectrogram(data)\n","    mask = np.isnan(data)\n","    data[mask] = -1\n","    data = np.clip(data, np.exp(-6), np.exp(10))\n","    data = np.log(data)\n","    \n","    return data \n","\n","def preprocess(path_to_parquet):\n","    data = pd.read_parquet(path_to_parquet)\n","    data = data.fillna(-1).values[:, 1:].T\n","    data = np.clip(data, np.exp(-6), np.exp(10))\n","    data = np.log(data)\n","    \n","    return data\n","\n","\n","def normalize_datawide(data_point):\n","    \"\"\"The spectrogram data will be normalized data wide.\"\"\"\n","    eps = 1e-6\n","\n","    data_point = (data_point - Config.dataset_wide_mean) / (Config.dataset_wide_std + eps)\n","\n","    data_tensor = torch.unsqueeze(torch.Tensor(data_point), dim=0)\n","    data_point = Config.image_transform(data_tensor)\n","\n","    return data_point\n","\n","\n","def normalize_datawide_ownspec(data):\n","    \"\"\"The new spectrogram data will be normalized data wide.\"\"\"\n","    eps = 1e-6\n","    \n","    data = (data - Config.ownspec_mean) / (Config.ownspec_std + eps)\n","    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n","    data = Config.image_transform(data_tensor)\n","    \n","    return data\n","\n","\n","def normalize_instance_wise(data_point):\n","    \"\"\"The spectrogram data will be normalized instance wise.\"\"\"\n","    eps = 1e-6\n","    \n","    data_mean = data_point.mean(axis=(0, 1))\n","    data_std = data_point.std(axis=(0, 1))\n","    data_point = (data_point - data_mean) / (data_std + eps)\n","    \n","    data_tensor = torch.unsqueeze(torch.Tensor(data_point), dim=0)\n","    data_point = Config.image_transform(data_tensor)\n","    \n","    return data_point\n","\n","# Loop over samples\n","for index in submission.index:\n","    test_predictions_per_model = []\n","    \n","    preprocessed_data = preprocess(submission.iloc[index]['path_spec'])\n","    preprocessed_data_ownspec = preprocess_ownspec(submission.iloc[index]['path_eeg'])\n","    \n","    # Predict based on original EfficientnetB0 models. \n","    for i in range(len(models)):\n","        models[i].eval()\n","        \n","        current_parquet_data = normalize_instance_wise(preprocessed_data).unsqueeze(0)\n","        \n","        with torch.no_grad():\n","            model_output = models[i](current_parquet_data)\n","            current_model_prediction = F.softmax(model_output)[0].detach().cpu().numpy()\n","            \n","        test_predictions_per_model.append(current_model_prediction)\n","    \n","    # Predict based on hyperparameter optimized EffcientnetB1.\n","    for i in range(len(models_datawide)):\n","        models_datawide[i].eval()\n","        \n","        current_parquet_data = normalize_datawide(preprocessed_data).unsqueeze(0)\n","        \n","        with torch.no_grad():\n","            model_output = models_datawide[i](current_parquet_data)\n","            current_model_prediction = F.softmax(model_output)[0].detach().cpu().numpy()\n","            \n","        test_predictions_per_model.append(current_model_prediction)\n","    \n","    # Predict based on EfficientnetB1 model with new spectrograms.\n","    for i in range(len(models_ownspec)):\n","        models_ownspec[i].eval()\n","        \n","        current_parquet_data = normalize_datawide_ownspec(preprocessed_data_ownspec).unsqueeze(0)\n","        \n","        with torch.no_grad():\n","            model_output = models_ownspec[i](current_parquet_data)\n","            current_model_prediction = F.softmax(model_output)[0].detach().cpu().numpy()\n","            \n","        test_predictions_per_model.append(current_model_prediction)\n","    \n","    # The mean of all models is taken.\n","    ensemble_prediction = np.mean(test_predictions_per_model,axis=0)\n","    \n","    test_predictions.append(ensemble_prediction)\n","\n","test_predictions = np.array(test_predictions)\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save the predictions\n","predss_3 = test_predictions\n","predss_3"]},{"cell_type":"markdown","metadata":{},"source":["# Submission Model 1 + Model 2 + Model 3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Combine the predictions\n","submission=pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n","labels=['seizure','lpd','gpd','lrda','grda','other']\n","for i in range(len(labels)):\n","    submission[f'{labels[i]}_vote']=(predss_1[:,i] * 0.45 + predss_2[:, i] * 0.15 + predss_3[:, i] * 0.40)\n","submission.to_csv(\"submission.csv\",index=None)\n","display(submission.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n","submission.iloc[:,-6:].sum(axis=1)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4382744,"sourceId":7752462,"sourceType":"datasetVersion"},{"datasetId":4571300,"sourceId":7805987,"sourceType":"datasetVersion"},{"datasetId":4574876,"sourceId":7810897,"sourceType":"datasetVersion"},{"datasetId":4417235,"isSourceIdPinned":true,"sourceId":7818976,"sourceType":"datasetVersion"},{"sourceId":160674831,"sourceType":"kernelVersion"},{"sourceId":160700706,"sourceType":"kernelVersion"},{"sourceId":165876189,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":15.163826,"end_time":"2024-03-10T23:52:22.657859","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-03-10T23:52:07.494033","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"015f0a06fb8d42baa8270ae0ab69d84d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"023a3f0d3a024ed49425226d4351937b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccb38c8526a84f2cbf6e8b5e8451b93a","placeholder":"","style":"IPY_MODEL_c4d1e4e5a4684bd3b3e122d2589cfdde","value":"Inference: 100%"}},"02e96c1c0cd9411ebbf34cc0ff76b9cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05c19c085d6f4fb4b94fe24b8d03709b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0817a39cf9d7494e9e8ece7ed886ab76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"121926f21d414f148521383fcc8cd9de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13381780fa9749b8874dd4a1426d07c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17ca6f9647304da9b5856a94fe2dca18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ac3f130c41c44b4a7443ae271bb83be","IPY_MODEL_a6ec0a18fe7944a795c1393d2b313cba","IPY_MODEL_6a73848fcb4e453e8e33e8be270c61cb"],"layout":"IPY_MODEL_b1ee18f01d604b17967d737b34c2845a"}},"19c28679e5bb42c394593c1eb8e4c30f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d7850e6b46c45e398f0ea304ff37f8f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e337f77a578a4d4aac5bf718ef03558a","value":1}},"1ac8dc03e9804667ad48594795e30d66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c5269f7a38c4b4287fc548db2cf2c4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"265549ed53264cbb954f26538c93a6e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3015868641054212a0bea1336437197c","placeholder":"","style":"IPY_MODEL_488711c03fee4974a7133db1082c1e42","value":"Inference: 100%"}},"2c02a1c6d00e4b2baac0ec990aef553b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2decb6ee8228485998f8875285000122":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_265549ed53264cbb954f26538c93a6e5","IPY_MODEL_abdb1742bf034a07a00165ab8f380458","IPY_MODEL_bb23792756414212aa46a862ddccef26"],"layout":"IPY_MODEL_71d714e6473d462b98a66f51636c508e"}},"3015868641054212a0bea1336437197c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f0c4b70020406f9d95eb627e567c82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd373c7f43d94daa9bd319be332c932e","placeholder":"","style":"IPY_MODEL_bbdb4325d8414ed180d1117cbfe45be5","value":"Inference: 100%"}},"3781be134bb94b3bbca5b8dd92f1cf00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38d201d56e5547c6ab3f4ce7d69e77c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a254fc5132c4d99a4d4e0d848e66184":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f1b83045bac43988fd0a0ec22361d9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e142dd5e8f425b9e8166959b491856":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13381780fa9749b8874dd4a1426d07c8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96c289e153a04548bcebfed779fe1784","value":1}},"4567c065c7e04b818efc62f9fbe6e42d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"488711c03fee4974a7133db1082c1e42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d7850e6b46c45e398f0ea304ff37f8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"532a4305b04f4834b2d62fce95e144ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fda4c8125dd84649a8335ad4fe5011a4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbc6dd04e93044d7846721269bae49d5","value":1}},"5643931a0bed4c5cbbfa160e353800ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bab92f13e624a98b65157ae2e1aa51e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bf05e3bb19342bd96818f0e18fa7259":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63c82603ef6a4cae9ca422c9d27e4479":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f1b83045bac43988fd0a0ec22361d9e","placeholder":"","style":"IPY_MODEL_1ac8dc03e9804667ad48594795e30d66","value":"Inference: 100%"}},"671b3143e72e4bbd85678e3d03ad0ae7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63c82603ef6a4cae9ca422c9d27e4479","IPY_MODEL_42e142dd5e8f425b9e8166959b491856","IPY_MODEL_9b913b16867043f09dd13ab638869d2f"],"layout":"IPY_MODEL_38d201d56e5547c6ab3f4ce7d69e77c5"}},"6a73848fcb4e453e8e33e8be270c61cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_846e10b5080d445f90a90037a3f6afcd","placeholder":"","style":"IPY_MODEL_6bf7a86ee3fc4821821d37b978d6e110","value":" 1/? [00:00&lt;00:00, 42.56it/s]"}},"6bf7a86ee3fc4821821d37b978d6e110":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70536c186c1c49aaa250faf33f925135":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d7802fec012424bafc33c49d49ee77d","IPY_MODEL_b8c53e32a14242ff83850c1c2b9a9013","IPY_MODEL_890be560a45e47358c0ed6b300e0ff49"],"layout":"IPY_MODEL_02e96c1c0cd9411ebbf34cc0ff76b9cf"}},"70b210d2173c4fa0ae92ba523439962c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71d714e6473d462b98a66f51636c508e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ae3c2511154d3da5df7ec885d018ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d7802fec012424bafc33c49d49ee77d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef1ce70888ed4464a6a2ad7adee20d33","placeholder":"","style":"IPY_MODEL_3a254fc5132c4d99a4d4e0d848e66184","value":"Inference: 100%"}},"846e10b5080d445f90a90037a3f6afcd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84725fc4d3674255b30f088d4aea769f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87894f24e8d34d458c563cf32268721b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_015f0a06fb8d42baa8270ae0ab69d84d","placeholder":"","style":"IPY_MODEL_5643931a0bed4c5cbbfa160e353800ef","value":" 1/1 [00:00&lt;00:00,  1.30test_batch/s]"}},"890be560a45e47358c0ed6b300e0ff49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bab92f13e624a98b65157ae2e1aa51e","placeholder":"","style":"IPY_MODEL_2c02a1c6d00e4b2baac0ec990aef553b","value":" 1/1 [00:00&lt;00:00, 33.66test_batch/s]"}},"8e6c295fc89a4a4386c60c243a3f6e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec5b41c25bb145959f2fcefe17ab3261","placeholder":"","style":"IPY_MODEL_05c19c085d6f4fb4b94fe24b8d03709b","value":" 1/1 [00:00&lt;00:00, 35.19test_batch/s]"}},"96c289e153a04548bcebfed779fe1784":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"982e7cfd5dca48118ba497e6f9eb7df0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ab77129f6ef418da151b75a7bbee449":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ac3f130c41c44b4a7443ae271bb83be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c5269f7a38c4b4287fc548db2cf2c4e","placeholder":"","style":"IPY_MODEL_3781be134bb94b3bbca5b8dd92f1cf00","value":""}},"9b913b16867043f09dd13ab638869d2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ab77129f6ef418da151b75a7bbee449","placeholder":"","style":"IPY_MODEL_5bf05e3bb19342bd96818f0e18fa7259","value":" 1/1 [00:00&lt;00:00, 30.31test_batch/s]"}},"a6ec0a18fe7944a795c1393d2b313cba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb2effe3bfb54ae6af5a71d6cf848ab4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70b210d2173c4fa0ae92ba523439962c","value":1}},"abdb1742bf034a07a00165ab8f380458":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84725fc4d3674255b30f088d4aea769f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_982e7cfd5dca48118ba497e6f9eb7df0","value":1}},"b1ee18f01d604b17967d737b34c2845a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b87c529a4cd342fc891785b80878bb90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33f0c4b70020406f9d95eb627e567c82","IPY_MODEL_532a4305b04f4834b2d62fce95e144ff","IPY_MODEL_87894f24e8d34d458c563cf32268721b"],"layout":"IPY_MODEL_121926f21d414f148521383fcc8cd9de"}},"b8c53e32a14242ff83850c1c2b9a9013":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76ae3c2511154d3da5df7ec885d018ad","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4567c065c7e04b818efc62f9fbe6e42d","value":1}},"ba6dde1f6d89429f9d8ed5013a947070":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb23792756414212aa46a862ddccef26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba6dde1f6d89429f9d8ed5013a947070","placeholder":"","style":"IPY_MODEL_e1451ad05eae4b289440467cf341493a","value":" 1/1 [00:00&lt;00:00, 31.49test_batch/s]"}},"bbdb4325d8414ed180d1117cbfe45be5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4d1e4e5a4684bd3b3e122d2589cfdde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb2effe3bfb54ae6af5a71d6cf848ab4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cbc6dd04e93044d7846721269bae49d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccb38c8526a84f2cbf6e8b5e8451b93a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd373c7f43d94daa9bd319be332c932e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1451ad05eae4b289440467cf341493a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e337f77a578a4d4aac5bf718ef03558a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec5b41c25bb145959f2fcefe17ab3261":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef1ce70888ed4464a6a2ad7adee20d33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb9ca4a41dd466ba8782ed4e721a640":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_023a3f0d3a024ed49425226d4351937b","IPY_MODEL_19c28679e5bb42c394593c1eb8e4c30f","IPY_MODEL_8e6c295fc89a4a4386c60c243a3f6e3e"],"layout":"IPY_MODEL_0817a39cf9d7494e9e8ece7ed886ab76"}},"fda4c8125dd84649a8335ad4fe5011a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
